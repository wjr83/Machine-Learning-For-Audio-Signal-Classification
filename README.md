# Machine-Learning-For-Audio-Signal-Classification
This project was an exploration of ten machine-learning models to classify audio samples from the TinySOL audio dataset into instrument types and instrument families. The models evaluated in the experiment are VGGish, K-Nearest-Neighbors (KNN), Support Vector Machine (SVM), Logistic Regression, Random Forest, Decision Tree, Gaussian Naive Bayes, Conv1D, Conv2D, and the Long Short-Term Memory (LSTM) model. Techniques for fine-tuning these models and reducing the high dimensionality of features to enhance performance were explored. The outcome of the experiment showed that the three CNN models (Conv1D, Conv2D, and LSTM) outperformed all other models in this classification task of both instrument type and family type. In contrast, the Gaussian Naive Bayes model showed the worst performance before and after relying on Principal Component Analysis (PCA) to reduce the dimensionality of the data. These findings underscore the effectiveness of CNN models in audio classification tasks and highlight the limitations of Gaussian Naive Bayes in this context. Our work contributes to the growing field of audio classification by providing insights into the performance of various machine-learning models on an audio dataset.
